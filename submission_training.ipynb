{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import yaml\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "# from keras import layers\n",
        "import tensorflow as tf\n",
        "from tensorflow import data as tf_data\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
        "import matplotlib.pyplot as plt\n",
        "from pprint import pprint\n",
        "\n",
        "print(\"Number of available GPUs: \", len(tf.config.list_physical_devices('GPU')))\n",
        "\n",
        "# read configuration file\n",
        "with open('config.yml', 'r') as f:\n",
        "    config = yaml.load(f, Loader=yaml.SafeLoader)\n",
        "\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if not gpus:\n",
        "    print(\"No GPUs found.\")\n",
        "else:\n",
        "    try:\n",
        "        if len(gpus) > 1:\n",
        "            tf.config.set_visible_devices([gpus[0]], 'GPU')  # make only GPU 0 visible\n",
        "            tf.config.experimental.set_memory_growth(gpus[0], True)\n",
        "            print(\"Using GPU 0.\")\n",
        "        else:\n",
        "            tf.config.set_visible_devices([gpus[0]], 'GPU')\n",
        "            tf.config.experimental.set_memory_growth(gpus[0], True)\n",
        "            print(\"Only one GPU available; using GPU 0.\")   \n",
        "    except Exception as e:\n",
        "        print(\"Failed to set visible GPU:\", e)\n",
        "\n",
        "print(\"Visible GPUs:\", tf.config.list_physical_devices('GPU'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The entire processed dataset is contained within `dataset.npz`, so load it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_dir = config['data_dir']\n",
        "\n",
        "with np.load(os.path.join(data_dir, 'dataset.npz')) as data:\n",
        "    hsc_lenses = data['hsc_lens']\n",
        "    hsc_nonlenses = data['hsc_nonlens']\n",
        "    slsim_lenses = data['slsim_lens']\n",
        "    slsim_nonlenses = data['slsim_nonlens']\n",
        "\n",
        "print(f'hsc_lens: {hsc_lenses.shape}')\n",
        "print(f'hsc_nonlens: {hsc_nonlenses.shape}')\n",
        "print(f'slsim_lens: {slsim_lenses.shape}')\n",
        "print(f'slsim_nonlens: {slsim_nonlenses.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Take a quick look at the four parts of the dataset: \n",
        "1. HSC Lenses\n",
        "2. HSC Nonlenses\n",
        "3. SLSim Lenses\n",
        "4. SLSim Nonlenses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(11.4, 12), constrained_layout=True)\n",
        "\n",
        "datasets = [\n",
        "    (slsim_lenses, \"slsim_lenses\"),\n",
        "    (hsc_lenses, \"hsc_lenses\"),\n",
        "    (slsim_nonlenses, \"slsim_nonlenses\"),\n",
        "    (hsc_nonlenses, \"hsc_nonlenses\"),\n",
        "]\n",
        "\n",
        "for ax, (images, title) in zip(axes.flat, datasets):\n",
        "    grid_size = min(25, len(images))\n",
        "    grid_rows = grid_cols = int(np.ceil(np.sqrt(grid_size)))\n",
        "    for i in range(grid_size):\n",
        "        row = i // grid_cols\n",
        "        col = i % grid_cols\n",
        "        sub_ax = ax.inset_axes([col/grid_cols, 1-row/grid_rows-1/grid_rows, 1/grid_cols, 1/grid_rows])\n",
        "        sub_ax.imshow(images[i][:,:,:3])\n",
        "        sub_ax.axis(\"off\")  # Hide axes for each image\n",
        "    ax.set_title(title)\n",
        "    ax.axis(\"off\")  # Hide main axes\n",
        "\n",
        "plt.suptitle('Dataset Sample')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Organize these four pieces into `data` and `labels` so that we can import it in a way that Tensorflow likes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = np.concatenate([hsc_lenses, slsim_lenses, hsc_nonlenses, slsim_nonlenses], axis=0)\n",
        "labels = np.array(([1] * (len(hsc_lenses) + len(slsim_lenses))) + ([0] * (len(hsc_nonlenses) + len(slsim_nonlenses))), dtype=np.uint8)\n",
        "print(data.shape)\n",
        "print(labels.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import the data and labels to a Tensorflow `Dataset`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ds = tf_data.Dataset.from_tensor_slices((data, labels))\n",
        "ds = ds.shuffle(buffer_size=len(labels), reshuffle_each_iteration=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Split the whole dataset into a training, validation, and test set. The training and validation sets are used in the training process, and the test set is used to evaluate the model's performance against data it hasn't been trained on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate split sizes\n",
        "total_size = len(labels)\n",
        "train_size = int(0.95 * total_size)\n",
        "val_size = total_size - train_size\n",
        "print(f'end={total_size}, train={train_size}, val={val_size}')\n",
        "\n",
        "# Split the dataset\n",
        "train_ds = ds.take(train_size)\n",
        "val_ds = ds.skip(train_size).take(val_size)\n",
        "\n",
        "print(f\"Train size: {train_ds.cardinality()}, Val size: {val_ds.cardinality()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\"Data augmentation\" is a way of increasing the size of our training set, which makes the neural net perform better. Here, we're randomly flipping and rotating the images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_augmentation_layers = [\n",
        "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "    layers.RandomRotation(0.25),\n",
        "]\n",
        "\n",
        "def data_augmentation(images):\n",
        "    for layer in data_augmentation_layers:\n",
        "        images = layer(images)\n",
        "    return images\n",
        "\n",
        "# Apply `data_augmentation` to the training images.\n",
        "train_ds = train_ds.map(\n",
        "    lambda img, label: (data_augmentation(img), label),\n",
        "    num_parallel_calls=tf_data.AUTOTUNE,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prefetching samples in GPU memory helps maximize GPU utilization.\n",
        "train_ds = train_ds.batch(256).prefetch(tf_data.AUTOTUNE)\n",
        "val_ds = val_ds.batch(256).prefetch(tf_data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Build the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def make_model(input_shape, num_classes):\n",
        "#     inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "#     # Entry block\n",
        "#     x = layers.Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")(inputs)\n",
        "#     x = layers.BatchNormalization()(x)\n",
        "#     x = layers.MaxPooling2D((2, 2))(x)\n",
        "\n",
        "#     x = layers.Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\")(x)\n",
        "#     x = layers.BatchNormalization()(x)\n",
        "#     x = layers.MaxPooling2D((2, 2))(x)\n",
        "\n",
        "#     x = layers.Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\")(x)\n",
        "#     x = layers.BatchNormalization()(x)\n",
        "#     x = layers.MaxPooling2D((2, 2))(x)\n",
        "\n",
        "#     x = layers.Conv2D(512, (3, 3), padding=\"same\", activation=\"relu\")(x)\n",
        "#     x = layers.BatchNormalization()(x)\n",
        "#     x = layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "#     x = layers.Dropout(0.5)(x)\n",
        "#     if num_classes == 2:\n",
        "#         units = 1\n",
        "#     else:\n",
        "#         units = num_classes\n",
        "\n",
        "#     outputs = layers.Dense(units, activation=None)(x)\n",
        "    \n",
        "#     return models.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "v5 model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def make_model(input_shape, num_classes, l2=1e-4):\n",
        "#     inputs = keras.Input(shape=input_shape)\n",
        "#     reg = keras.regularizers.l2(l2)\n",
        "\n",
        "#     def conv_bn_act(x, filters, kernel_size=3, strides=1):\n",
        "#         x = layers.Conv2D(filters, kernel_size, strides=strides, padding=\"same\",\n",
        "#                           kernel_regularizer=reg, use_bias=False)(x)\n",
        "#         x = layers.BatchNormalization()(x)\n",
        "#         return layers.Activation(\"relu\")(x)\n",
        "\n",
        "#     def bottleneck_block(x, filters, strides=1):\n",
        "#         # Bottleneck: 1x1 reduce -> 3x3 -> 1x1 expand\n",
        "#         shortcut = x\n",
        "#         reduced = max(1, filters // 4)\n",
        "\n",
        "#         x = layers.Conv2D(reduced, 1, strides=strides, padding=\"same\",\n",
        "#                           kernel_regularizer=reg, use_bias=False)(x)\n",
        "#         x = layers.BatchNormalization()(x)\n",
        "#         x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "#         x = layers.Conv2D(reduced, 3, strides=1, padding=\"same\",\n",
        "#                           kernel_regularizer=reg, use_bias=False)(x)\n",
        "#         x = layers.BatchNormalization()(x)\n",
        "#         x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "#         x = layers.Conv2D(filters, 1, strides=1, padding=\"same\",\n",
        "#                           kernel_regularizer=reg, use_bias=False)(x)\n",
        "#         x = layers.BatchNormalization()(x)\n",
        "\n",
        "#         # projection if shape/stride differs\n",
        "#         if strides != 1 or shortcut.shape[-1] != filters:\n",
        "#             shortcut = layers.Conv2D(filters, 1, strides=strides, padding=\"same\",\n",
        "#                                      kernel_regularizer=reg, use_bias=False)(shortcut)\n",
        "#             shortcut = layers.BatchNormalization()(shortcut)\n",
        "\n",
        "#         x = layers.add([x, shortcut])\n",
        "#         return layers.Activation(\"relu\")(x)\n",
        "\n",
        "#     # Stem (kept gentle because input is small)\n",
        "#     x = layers.Conv2D(64, 3, strides=1, padding=\"same\", kernel_regularizer=reg, use_bias=False)(inputs)\n",
        "#     x = layers.BatchNormalization()(x)\n",
        "#     x = layers.Activation(\"relu\")(x)\n",
        "#     x = layers.MaxPooling2D(2, strides=2, padding=\"same\")(x)\n",
        "\n",
        "#     # Residual stages (filters, blocks, first_block_stride)\n",
        "#     stages = [\n",
        "#         (128, 2, 1),\n",
        "#         (256, 2, 2),\n",
        "#         (512, 2, 2),\n",
        "#     ]\n",
        "#     for filters, blocks, first_stride in stages:\n",
        "#         x = bottleneck_block(x, filters, strides=first_stride)\n",
        "#         for _ in range(blocks - 1):\n",
        "#             x = bottleneck_block(x, filters, strides=1)\n",
        "\n",
        "#     # Head\n",
        "#     x = layers.GlobalAveragePooling2D()(x)\n",
        "#     x = layers.Dropout(0.4)(x)\n",
        "#     units = 1 if num_classes == 2 else num_classes\n",
        "#     outputs = layers.Dense(units, activation=None, kernel_regularizer=reg)(x)\n",
        "\n",
        "#     return keras.Model(inputs, outputs, name=\"resnet_like_v1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "v4 model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_model(input_shape, num_classes):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    num_bands = input_shape[2]\n",
        "\n",
        "    # Entry block\n",
        "    x = layers.Conv2D(128, num_bands, strides=2, padding=\"same\")(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    previous_block_activation = x  # Set aside residual\n",
        "\n",
        "    for size in [256, 512, 728]:\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.SeparableConv2D(size, num_bands, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.SeparableConv2D(size, num_bands, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.MaxPooling2D(num_bands, strides=2, padding=\"same\")(x)\n",
        "\n",
        "        # Project residual\n",
        "        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n",
        "            previous_block_activation\n",
        "        )\n",
        "        x = layers.add([x, residual])  # Add back residual\n",
        "        previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "    x = layers.SeparableConv2D(1024, num_bands, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    if num_classes == 2:\n",
        "        units = 1\n",
        "    else:\n",
        "        units = num_classes\n",
        "\n",
        "    x = layers.Dropout(0.25)(x)\n",
        "    # We specify activation=None so as to return logits\n",
        "    outputs = layers.Dense(units, activation=None)(x)\n",
        "    return keras.Model(inputs, outputs)\n",
        "\n",
        "model = make_model(input_shape=(41, 41, 5), num_classes=2)\n",
        "keras.utils.plot_model(model, show_shapes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "epochs = 100  # 250 should be better\n",
        "\n",
        "# ---- LR schedule (epoch-based warmup + cosine) ----\n",
        "lr_max = 1e-3     # your current LR\n",
        "lr_min = 1e-6     # floor\n",
        "warmup_epochs = 5 # tweak 3â€“10 if needed\n",
        "\n",
        "def warmup_cosine(epoch, lr):\n",
        "    if epoch < warmup_epochs:\n",
        "        # linear warmup from 0 -> lr_max\n",
        "        return lr_max * (epoch + 1) / float(warmup_epochs)\n",
        "    # cosine decay from lr_max -> lr_min over remaining epochs\n",
        "    progress = (epoch - warmup_epochs) / float(max(1, epochs - warmup_epochs))\n",
        "    return lr_min + 0.5 * (lr_max - lr_min) * (1 + math.cos(math.pi * min(1.0, progress)))\n",
        "\n",
        "lr_scheduler = keras.callbacks.LearningRateScheduler(warmup_cosine, verbose=0)\n",
        "\n",
        "# training\n",
        "model = make_model(input_shape=(41, 41, 5), num_classes=2)\n",
        "# keras.utils.plot_model(model, show_shapes=True)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=lr_max),  # peak LR; callback will override per-epoch\n",
        "    loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "    metrics=[keras.metrics.BinaryAccuracy(name=\"acc\")],\n",
        ")\n",
        "\n",
        "early_stopping = keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=6,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1,\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "    # early_stopping, \n",
        "    lr_scheduler\n",
        "    ]\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_ds,\n",
        "    callbacks=callbacks,\n",
        ")\n",
        "\n",
        "history_dict = history.history\n",
        "\n",
        "# convert lists to numpy arrays for reliable saving\n",
        "history_np = {k: np.array(v) for k, v in history_dict.items()}\n",
        "\n",
        "os.makedirs('logs', exist_ok=True)\n",
        "npz_path = os.path.join('logs', 'history_v4_retrain.npz')\n",
        "np.savez_compressed(npz_path, **history_np)\n",
        "\n",
        "# also save human-readable YAML\n",
        "yml_path = os.path.join('logs', 'history_v4_retrain.yml')\n",
        "with open(yml_path, 'w') as f:\n",
        "    yaml.dump(history_dict, f)\n",
        "\n",
        "print(f\"Saved training history to: {npz_path} and {yml_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot the training and validation accuracy to sanity check that the training is going as expected. We can identify overfitting and underfitting by looking at this figure:\n",
        "- Ideal Scenario: Training accuracy steadily increases and levels off at a high value. Validation accuracy follows closely and also levels off at a high value.\n",
        "- Overfitting Scenario: Training accuracy keeps increasing and may reach 100%, but validation accuracy peaks early and then decreases.\n",
        "- Underfitting Scenario: Both training and validation accuracy remain low."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "accuracy = history.history['acc']\n",
        "val_accuracy = history.history['val_acc']\n",
        "\n",
        "_, ax = plt.subplots(1, 2, figsize=(7, 3), constrained_layout=True)\n",
        "epoch_list = range(1, len(loss) + 1)\n",
        "\n",
        "ax[0].plot(epoch_list, loss, 'bo-', label='Training')\n",
        "ax[0].plot(epoch_list, val_loss, 'ro-', label='Validation')\n",
        "ax[0].set_title('Loss')\n",
        "ax[0].set_xlabel('Epochs')\n",
        "ax[0].set_ylabel('Loss')\n",
        "# ax[0].set_ylim(0, 1)\n",
        "ax[0].legend()\n",
        "\n",
        "ax[1].plot(epoch_list, accuracy, 'bo-', label='Training')\n",
        "ax[1].plot(epoch_list, val_accuracy, 'ro-', label='Validation')\n",
        "ax[1].set_title('Accuracy')\n",
        "ax[1].set_xlabel('Epochs')\n",
        "ax[1].set_ylabel('Accuracy')\n",
        "# ax[1].set_ylim(0, 1)\n",
        "ax[1].legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save(f'/data/bwedig/lsst-strong-lens-data-challenge/models/v4_retrain.keras')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "lsst-data-challenge",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
